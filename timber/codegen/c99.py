"""C99 code emitter — generates portable C99 source for inference.

Output guarantees:
- No dynamic memory allocation
- No recursion
- No floating-point unless target supports it
- No standard library dependencies beyond <stdint.h> and <string.h>
- Deterministic execution time
"""

from __future__ import annotations

import os
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Optional

from timber.ir.model import (
    TimberIR,
    TreeEnsembleStage,
    ScalerStage,
    ImputerStage,
    LinearStage,
    Objective,
    PrecisionMode,
)


@dataclass
class TargetSpec:
    """Hardware target specification for code generation."""
    arch: str = "x86_64"
    features: list[str] = field(default_factory=list)
    os: str = "linux"
    abi: str = "systemv"
    precision: PrecisionMode = PrecisionMode.FLOAT32
    output_format: str = "c_source"
    strip_symbols: bool = False


@dataclass
class C99Output:
    """The generated C99 source package."""
    model_c: str
    model_h: str
    model_data_c: str
    cmakelists: str
    makefile: str

    def write(self, output_dir: str | Path) -> list[str]:
        """Write all files to the output directory. Returns list of written paths."""
        out = Path(output_dir)
        out.mkdir(parents=True, exist_ok=True)

        files = {
            "model.c": self.model_c,
            "model.h": self.model_h,
            "model_data.c": self.model_data_c,
            "CMakeLists.txt": self.cmakelists,
            "Makefile": self.makefile,
        }

        written = []
        for name, content in files.items():
            path = out / name
            path.write_text(content, encoding="utf-8")
            written.append(str(path))

        return written


class C99Emitter:
    """Emits C99 source code from optimized Timber IR."""

    def __init__(self, target: Optional[TargetSpec] = None):
        self.target = target or TargetSpec()

    def emit(self, ir: TimberIR) -> C99Output:
        """Generate the full C99 source package from the IR."""
        ensemble = ir.get_tree_ensemble()
        if ensemble is None:
            raise ValueError("No tree ensemble found in IR pipeline")

        model_h = self._emit_header(ir, ensemble)
        model_data_c = self._emit_data(ir, ensemble)
        model_c = self._emit_inference(ir, ensemble)
        cmakelists = self._emit_cmake(ir)
        makefile = self._emit_makefile(ir)

        return C99Output(
            model_c=model_c,
            model_h=model_h,
            model_data_c=model_data_c,
            cmakelists=cmakelists,
            makefile=makefile,
        )

    def _emit_header(self, ir: TimberIR, ensemble: TreeEnsembleStage) -> str:
        """Generate model.h — the public C header."""
        n_features = ensemble.n_features
        n_outputs = 1 if ensemble.n_classes <= 2 else ensemble.n_classes
        float_type = self._float_type()

        lines = [
            "/* model.h — Timber compiled model inference header */",
            "/* Generated by Timber v0.1 — DO NOT EDIT */",
            "",
            "#ifndef TIMBER_MODEL_H",
            "#define TIMBER_MODEL_H",
            "",
            "#include <stdint.h>",
            "#include <stddef.h>",
            "",
            "#ifdef __cplusplus",
            'extern "C" {',
            "#endif",
            "",
            "/* ABI version — bump on breaking changes to the public API. */",
            "#define TIMBER_ABI_VERSION  1",
            '#define TIMBER_VERSION     "0.1.0"',
            "",
            f"#define TIMBER_N_FEATURES {n_features}",
            f"#define TIMBER_N_OUTPUTS  {n_outputs}",
            f"#define TIMBER_N_TREES    {ensemble.n_trees}",
            f"#define TIMBER_MAX_DEPTH  {ensemble.max_depth}",
            "",
            "/* Opaque context — holds compiled model state. */",
            "/* Read-only after init; thread-safe for concurrent inference. */",
            "typedef struct TimberCtx TimberCtx;",
            "",
            "/* Error codes */",
            "#define TIMBER_OK          0",
            "#define TIMBER_ERR_NULL   -1",
            "#define TIMBER_ERR_INIT   -2",
            "#define TIMBER_ERR_BOUNDS -3",
            "",
            "/* Initialize the model context. Call once at startup. */",
            "/* Returns TIMBER_OK on success, negative error code on failure. */",
            "int timber_init(TimberCtx** ctx);",
            "",
            "/* Return the ABI version this library was compiled with. */",
            "int timber_abi_version(void);",
            "",
            "/* Optional logging callback. Set to NULL to disable. */",
            "/* Signature: void my_logger(int level, const char* msg) */",
            "/* Levels: 0=error, 1=warn, 2=info, 3=debug */",
            "typedef void (*timber_log_fn)(int level, const char* msg);",
            "void timber_set_log_callback(timber_log_fn fn);",
            "",
            "/* Return a human-readable string for an error code. */",
            "const char* timber_strerror(int code);",
            "",
            "/* Free the model context. */",
            "void timber_free(TimberCtx* ctx);",
            "",
            "/* Run inference on a batch of samples. */",
            "/*",
            f" *  inputs:    input feature matrix, row-major, shape [n_samples x {n_features}]",
            " *  n_samples: number of samples in the batch",
            f" *  outputs:   output buffer, pre-allocated, shape [n_samples x {n_outputs}]",
            " *  ctx:       model context from timber_init",
            " *",
            " *  Returns 0 on success, non-zero on error.",
            " */",
            f"int timber_infer(",
            f"    const {float_type}*  inputs,",
            f"    int                  n_samples,",
            f"    {float_type}*        outputs,",
            f"    const TimberCtx*     ctx",
            ");",
            "",
            "/* Single-sample inference convenience wrapper. */",
            f"int timber_infer_single(",
            f"    const {float_type}  inputs[TIMBER_N_FEATURES],",
            f"    {float_type}        outputs[TIMBER_N_OUTPUTS],",
            f"    const TimberCtx*    ctx",
            ");",
            "",
            "#ifdef __cplusplus",
            "}",
            "#endif",
            "",
            "#endif /* TIMBER_MODEL_H */",
        ]
        return "\n".join(lines) + "\n"

    def _emit_data(self, ir: TimberIR, ensemble: TreeEnsembleStage) -> str:
        """Generate model_data.c — static const arrays for tree data."""
        float_type = self._float_type()
        lines = [
            "/* model_data.c — Timber compiled model data */",
            "/* Generated by Timber v0.1 — DO NOT EDIT */",
            "",
            '#include "model.h"',
            "#include <math.h>",
            "",
        ]

        # Emit node data as flat arrays per tree
        # For each tree: feature_indices, thresholds, left_children, right_children, leaf_values
        for tree in ensemble.trees:
            tid = tree.tree_id
            n_nodes = len(tree.nodes)

            # Feature indices
            feat_vals = ", ".join(str(n.feature_index) for n in tree.nodes)
            lines.append(f"static const int32_t tree_{tid}_features[{n_nodes}] = {{{feat_vals}}};")

            # Thresholds
            thresh_vals = ", ".join(self._format_float(n.threshold) for n in tree.nodes)
            lines.append(f"static const {float_type} tree_{tid}_thresholds[{n_nodes}] = {{{thresh_vals}}};")

            # Left children
            left_vals = ", ".join(str(n.left_child) for n in tree.nodes)
            lines.append(f"static const int32_t tree_{tid}_left[{n_nodes}] = {{{left_vals}}};")

            # Right children
            right_vals = ", ".join(str(n.right_child) for n in tree.nodes)
            lines.append(f"static const int32_t tree_{tid}_right[{n_nodes}] = {{{right_vals}}};")

            # Leaf values
            leaf_vals = ", ".join(self._format_float(n.leaf_value) for n in tree.nodes)
            lines.append(f"static const {float_type} tree_{tid}_leaves[{n_nodes}] = {{{leaf_vals}}};")

            # Is-leaf flags
            is_leaf_vals = ", ".join("1" if n.is_leaf else "0" for n in tree.nodes)
            lines.append(f"static const int8_t tree_{tid}_is_leaf[{n_nodes}] = {{{is_leaf_vals}}};")

            # Default-left flags
            def_left_vals = ", ".join("1" if n.default_left else "0" for n in tree.nodes)
            lines.append(f"static const int8_t tree_{tid}_default_left[{n_nodes}] = {{{def_left_vals}}};")

            lines.append(f"#define TREE_{tid}_N_NODES {n_nodes}")
            lines.append("")

        # Base score
        lines.append(f"static const {float_type} TIMBER_BASE_SCORE = {self._format_float(ensemble.base_score)};")
        lines.append("")

        return "\n".join(lines) + "\n"

    def _emit_inference(self, ir: TimberIR, ensemble: TreeEnsembleStage) -> str:
        """Generate model.c — the compiled inference logic."""
        float_type = self._float_type()
        n_features = ensemble.n_features
        n_outputs = 1 if ensemble.n_classes <= 2 else ensemble.n_classes
        n_trees = ensemble.n_trees

        lines = [
            "/* model.c — Timber compiled inference logic */",
            "/* Generated by Timber v0.1 — DO NOT EDIT */",
            "",
            '#include "model.h"',
            "#include <stdint.h>",
            "#include <stddef.h>",
            "#include <string.h>",
            "#include <math.h>",
            "",
        ]

        # Include the data file
        lines.append('#include "model_data.c"')
        lines.append("")

        # Context struct
        lines.extend([
            "/* Context structure — trivial for static models */",
            "struct TimberCtx {",
            "    int initialized;",
            "};",
            "",
            "static struct TimberCtx _default_ctx = {1};",
            "",
        ])

        # Logging, strerror, init, free, ABI
        lines.extend([
            "/* --- Logging --- */",
            "static timber_log_fn _timber_log_cb = NULL;",
            "",
            "void timber_set_log_callback(timber_log_fn fn) { _timber_log_cb = fn; }",
            "",
            "static void timber_log(int level, const char* msg) {",
            "    if (_timber_log_cb) _timber_log_cb(level, msg);",
            "}",
            "",
            "const char* timber_strerror(int code) {",
            '    switch (code) {',
            '        case  0: return "TIMBER_OK";',
            '        case -1: return "TIMBER_ERR_NULL: null pointer argument";',
            '        case -2: return "TIMBER_ERR_INIT: context not initialized";',
            '        case -3: return "TIMBER_ERR_BOUNDS: argument out of bounds";',
            '        default: return "TIMBER_ERR_UNKNOWN";',
            "    }",
            "}",
            "",
            "int timber_abi_version(void) { return TIMBER_ABI_VERSION; }",
            "",
            "int timber_init(TimberCtx** ctx) {",
            "    if (ctx == NULL) {",
            '        timber_log(0, "timber_init: ctx is NULL");',
            "        return TIMBER_ERR_NULL;",
            "    }",
            "    *ctx = &_default_ctx;",
            '    timber_log(2, "timber_init: OK");',
            "    return TIMBER_OK;",
            "}",
            "",
            "void timber_free(TimberCtx* ctx) {",
            "    (void)ctx; /* static allocation, nothing to free */",
            "}",
            "",
        ])

        # Single-tree traversal function
        lines.extend([
            f"static {float_type} traverse_tree(",
            f"    const {float_type}* input,",
            "    const int32_t* features,",
            f"    const {float_type}* thresholds,",
            "    const int32_t* left_children,",
            "    const int32_t* right_children,",
            f"    const {float_type}* leaf_values,",
            "    const int8_t* is_leaf,",
            "    const int8_t* default_left,",
            "    int n_nodes",
            ") {",
            "    int node = 0;",
            f"    int max_iter = {ensemble.max_depth + 2};",
            "    while (max_iter-- > 0) {",
            "        if (node < 0 || node >= n_nodes) return 0.0f;",
            "        if (is_leaf[node]) return leaf_values[node];",
            "",
            "        int feat = features[node];",
            f"        {float_type} val = input[feat];",
            "",
            "        /* NaN handling: follow default direction */",
            "        if (val != val) { /* NaN check */",
            "            node = default_left[node] ? left_children[node] : right_children[node];",
            "        } else if (val < thresholds[node]) {",
            "            node = left_children[node];",
            "        } else {",
            "            node = right_children[node];",
            "        }",
            "    }",
            "    return 0.0f;",
            "}",
            "",
        ])


        # (softmax is inlined in double precision in timber_infer_single)

        # Single-sample inference (unrolled tree calls)
        lines.extend([
            f"int timber_infer_single(",
            f"    const {float_type}  inputs[TIMBER_N_FEATURES],",
            f"    {float_type}        outputs[TIMBER_N_OUTPUTS],",
            f"    const TimberCtx*    ctx",
            ") {",
            "    (void)ctx;",
        ])

        if ensemble.objective == Objective.MULTICLASS_CLASSIFICATION and ensemble.n_classes > 2:
            # Multi-class: accumulate per-class scores with double precision
            lines.append(f"    double scores[{ensemble.n_classes}];")
            lines.append("    int c;")
            lines.append(f"    for (c = 0; c < {ensemble.n_classes}; c++) scores[c] = 0.0;")
            lines.append("")

            # Trees are interleaved: tree i contributes to class (i % n_classes)
            for i, tree in enumerate(ensemble.trees):
                cls_idx = i % ensemble.n_classes
                lines.append(
                    f"    scores[{cls_idx}] += (double)traverse_tree(inputs, "
                    f"tree_{tree.tree_id}_features, tree_{tree.tree_id}_thresholds, "
                    f"tree_{tree.tree_id}_left, tree_{tree.tree_id}_right, "
                    f"tree_{tree.tree_id}_leaves, tree_{tree.tree_id}_is_leaf, "
                    f"tree_{tree.tree_id}_default_left, TREE_{tree.tree_id}_N_NODES);"
                )

            # Softmax in double precision
            lines.append("")
            lines.append(f"    {{ /* softmax */")
            lines.append(f"        double max_val = scores[0];")
            lines.append(f"        for (c = 1; c < {ensemble.n_classes}; c++)")
            lines.append(f"            if (scores[c] > max_val) max_val = scores[c];")
            lines.append(f"        double denom = 0.0;")
            lines.append(f"        for (c = 0; c < {ensemble.n_classes}; c++) {{")
            lines.append(f"            scores[c] = exp(scores[c] - max_val);")
            lines.append(f"            denom += scores[c];")
            lines.append(f"        }}")
            lines.append(f"        for (c = 0; c < {ensemble.n_classes}; c++)")
            lines.append(f"            outputs[c] = ({float_type})(scores[c] / denom);")
            lines.append(f"    }}")
        else:
            # Binary classification or regression: use double accumulator for precision
            lines.append("    double sum = (double)TIMBER_BASE_SCORE;")
            lines.append("")

            for tree in ensemble.trees:
                lines.append(
                    f"    sum += (double)traverse_tree(inputs, "
                    f"tree_{tree.tree_id}_features, tree_{tree.tree_id}_thresholds, "
                    f"tree_{tree.tree_id}_left, tree_{tree.tree_id}_right, "
                    f"tree_{tree.tree_id}_leaves, tree_{tree.tree_id}_is_leaf, "
                    f"tree_{tree.tree_id}_default_left, TREE_{tree.tree_id}_N_NODES);"
                )

            lines.append("")

            if ensemble.objective in (Objective.BINARY_CLASSIFICATION, Objective.REGRESSION_LOGISTIC):
                lines.append(f"    outputs[0] = ({float_type})(1.0 / (1.0 + exp(-sum)));")
            else:
                lines.append(f"    outputs[0] = ({float_type})sum;")

        lines.extend([
            "",
            "    return 0;",
            "}",
            "",
        ])

        # Batched inference
        lines.extend([
            f"int timber_infer(",
            f"    const {float_type}*  inputs,",
            f"    int                  n_samples,",
            f"    {float_type}*        outputs,",
            f"    const TimberCtx*     ctx",
            ") {",
            "    int i;",
            "    if (inputs == NULL || outputs == NULL) return TIMBER_ERR_NULL;",
            "    if (n_samples <= 0) return TIMBER_ERR_BOUNDS;",
            "",
            "    for (i = 0; i < n_samples; i++) {",
            f"        int rc = timber_infer_single(",
            f"            inputs + i * TIMBER_N_FEATURES,",
            f"            outputs + i * TIMBER_N_OUTPUTS,",
            f"            ctx",
            "        );",
            "        if (rc != 0) return rc;",
            "    }",
            "    return 0;",
            "}",
        ])

        return "\n".join(lines) + "\n"

    def _emit_cmake(self, ir: TimberIR) -> str:
        """Generate CMakeLists.txt for the compiled model."""
        lines = [
            "# CMakeLists.txt — Timber compiled model",
            "# Generated by Timber v0.1",
            "",
            "cmake_minimum_required(VERSION 3.10)",
            "project(timber_model C)",
            "",
            "set(CMAKE_C_STANDARD 99)",
            "set(CMAKE_C_STANDARD_REQUIRED ON)",
            "",
            "# Shared library",
            "add_library(timber_model SHARED model.c)",
            "target_include_directories(timber_model PUBLIC ${CMAKE_CURRENT_SOURCE_DIR})",
            "",
            "# Static library",
            "add_library(timber_model_static STATIC model.c)",
            "target_include_directories(timber_model_static PUBLIC ${CMAKE_CURRENT_SOURCE_DIR})",
            "set_target_properties(timber_model_static PROPERTIES OUTPUT_NAME timber_model)",
            "",
        ]

        # Add architecture-specific flags
        if "avx512f" in self.target.features:
            lines.append('target_compile_options(timber_model PRIVATE "-mavx512f" "-mavx512bw")')
            lines.append('target_compile_options(timber_model_static PRIVATE "-mavx512f" "-mavx512bw")')
        elif "avx2" in self.target.features:
            lines.append('target_compile_options(timber_model PRIVATE "-mavx2" "-mfma")')
            lines.append('target_compile_options(timber_model_static PRIVATE "-mavx2" "-mfma")')

        lines.extend([
            "",
            "# Optimization flags",
            'target_compile_options(timber_model PRIVATE "-O3" "-DNDEBUG")',
            'target_compile_options(timber_model_static PRIVATE "-O3" "-DNDEBUG")',
        ])

        return "\n".join(lines) + "\n"

    def _emit_makefile(self, ir: TimberIR) -> str:
        """Generate Makefile as a fallback build system."""
        arch_flags = ""
        if "avx512f" in self.target.features:
            arch_flags = "-mavx512f -mavx512bw"
        elif "avx2" in self.target.features:
            arch_flags = "-mavx2 -mfma"

        lines = [
            "# Makefile — Timber compiled model",
            "# Generated by Timber v0.1",
            "",
            "CC ?= gcc",
            f"CFLAGS = -std=c99 -O3 -DNDEBUG -fPIC -Wall -Wextra {arch_flags}".strip(),
            "",
            ".PHONY: all clean",
            "",
            "all: libtimber_model.so libtimber_model.a",
            "",
            "libtimber_model.so: model.c model_data.c model.h",
            "\t$(CC) $(CFLAGS) -shared -o $@ model.c -lm",
            "",
            "libtimber_model.a: model.c model_data.c model.h",
            "\t$(CC) $(CFLAGS) -c -o model.o model.c",
            "\tar rcs $@ model.o",
            "",
            "clean:",
            "\trm -f *.o *.so *.a",
        ]

        return "\n".join(lines) + "\n"

    def _float_type(self) -> str:
        if self.target.precision == PrecisionMode.FLOAT16:
            return "_Float16"
        return "float"

    @staticmethod
    def _format_float(value: float) -> str:
        if value == 0.0:
            return "0.0f"
        s = f"{value:.10g}"
        # Ensure there's a decimal point so the 'f' suffix is valid C
        if "." not in s and "e" not in s and "E" not in s:
            s += ".0"
        return s + "f"
